<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[elasticsearch]]></title>
    <url>%2F2018%2F05%2F28%2Felasticsearch%2F</url>
    <content type="text"><![CDATA[带着问题上路——ES是如何产生的？ 思考：大规模数据如何检索？如：当系统数据量上了10亿、100亿条的时候，我们在做系统架构的时候通常会从以下角度去考虑问题： 1）用什么数据库好？(mysql、sybase、oracle、达梦、神通、mongodb、hbase…) 2）如何解决单点故障；(lvs、F5、A10、Zookeep、MQ) 3）如何保证数据安全性；(热备、冷备、异地多活) 4）如何解决检索难题；(数据库代理中间件：mysql-proxy、Cobar、MaxScale等;) 5）如何解决统计分析问题；(离线、近实时) ###2. 传统数据库的应对解决方案 对于关系型数据，我们通常采用以下或类似架构去解决查询瓶颈和写入瓶颈： 解决要点： 1）通过主从备份解决数据安全性问题； 2）通过数据库代理中间件心跳监测，解决单点故障问题； 3）通过代理中间件将查询语句分发到各个slave节点进行查询，并汇总结果。 非关系型数据库的解决方案对于Nosql数据库，以mongodb为例，其它原理类似： 解决要点： 1）通过副本备份保证数据安全性； 2）通过节点竞选机制解决单点问题； 3）先从配置库检索分片信息，然后将请求分发到各个节点，最后由路由节点合并汇总结果。 4.另辟蹊径——完全把数据放入内存怎么样？我们知道，完全把数据放在内存中是不可靠的，实际上也不太现实，当我们的数据达到PB级别时，按照每个节点96G内存计算，在内存完全装满的数据情况下，我们需要的机器是：1PB=1024T=1048576G 节点数=1048576/96=10922个 实际上，考虑到数据备份，节点数往往在2.5万台左右。成本巨大决定了其不现实！ 从前面讨论我们了解到，把数据放在内存也好，不放在内存也好，都不能完完全全解决问题。 全部放在内存速度问题是解决了，但成本问题上来了。 为解决以上问题，从源头着手分析，通常会从以下方式来寻找方法： 1、存储数据时按有序存储； 2、将数据和索引分离； 3、压缩数据； 这就引出了Elasticsearch。 一、ES基础1.1 简介ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。 Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。 我们建立一个网站或应用程序，并要添加搜索功能，但是想要完成搜索工作的创建是非常困难的。我们希望搜索解决方案要运行速度快，我们希望能有一个零配置和一个完全免费的搜索模式，我们希望能够简单地使用JSON通过HTTP来索引数据，我们希望我们的搜索服务器始终可用，我们希望能够从一台开始并扩展到数百台，我们要实时搜索，我们要简单的多租户，我们希望建立一个云的解决方案。因此我们利用Elasticsearch来解决所有这些问题以及可能出现的更多其它问题。 详细介绍：百度百科 1.2 Lucene与ES关系？1）Lucene只是一个库。想要使用它，你必须使用Java来作为开发语言并将其直接集成到你的应用中，更糟糕的是，Lucene非常复杂，你需要深入了解检索的相关知识来理解它是如何工作的。 2）Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。 1.3 ES主要解决的问题1）检索相关数据 2）返回统计结果 3）速度要快 1.4 ES工作原理当ElasticSearch的节点启动后，它会利用多播(multicast)(或者单播，如果用户更改了配置)寻找集群中的其它节点，并与之建立连接。这个过程如下图所示： 1.5 ES核心概念 Cluster：集群。ES可以作为一个独立的单个搜索服务器。不过，为了处理大型数据集，实现容错和高可用性，ES可以运行在许多互相合作的服务器上。这些服务器的集合称为集群。 Node：节点形成集群的每个服务器称为节点。 Shard：分片当有大量的文档时，由于内存的限制、磁盘处理能力不足、无法足够快的响应客户端的请求等，一个节点可能不够。这种情况下，数据可以分为较小的分片。每个分片放到不同的服务器上。 当你查询的索引分布在多个分片上时，ES会把查询发送给每个相关的分片，并将结果组合在一起，而应用程序并不知道分片的存在。即：这个过程对用户来说是透明的。 Replia：副本为提高查询吞吐量或实现高可用性，可以使用分片副本。 副本是一个分片的精确复制，每个分片可以有零个或多个副本。ES中可以有许多相同的分片，其中之一被选择更改索引操作，这种特殊的分片称为主分片。 当主分片丢失时，如：该分片所在的数据不可用时，集群将副本提升为新的主分片。 全文检索全文检索就是对一篇文章进行索引，可以根据关键字搜索，类似于mysql里的like语句。 全文索引就是把内容根据词的意义进行分词，然后分别创建索引，例如”你们的激情是因为什么事情来的” 可能会被分词成：“你们“，”激情“，“什么事情“，”来“ 等token，这样当你搜索“你们” 或者 “激情” 都会把这句搜出来。 1.6 ES数据架构的主要概念（与关系数据库Mysql对比） （1）关系型数据库中的数据库（DataBase），等价于ES中的索引（Index）。 （2）一个数据库下面有N张表（Table），等价于1个索引Index下面有N多类型（Type）。 （3）一个数据库表（Table）下的数据由多行（ROW）多列（column，属性）组成，等价于1个Type由多个文档（Document）和多Field组成。 （4）在一个关系型数据库里面，schema定义了表、每个表的字段，还有表和字段之间的关系。 与之对应的，在ES中：Mapping定义索引下的Type的字段处理规则，即索引如何建立、索引类型、是否保存原始索引JSON文档、是否压缩原始JSON文档、是否需要分词处理、如何进行分词处理等。 （5）在数据库中的增insert、删delete、改update、查search操作等价于ES中的增PUT/POST、删Delete、改_update、查GET。 1.7 ELK是什么？ELK=elasticsearch+Logstash+kibana elasticsearch：后台分布式存储以及全文检索logstash: 日志加工、“搬运工”kibana：数据可视化展示。ELK架构为数据分布式存储、可视化查询和日志解析创建了一个功能强大的管理链。 三者相互配合，取长补短，共同完成分布式大数据处理工作。 1.8 ES特点和优势1）分布式实时文件存储，可将每一个字段存入索引，使其可以被检索到。 2）实时分析的分布式搜索引擎。 分布式：索引分拆成多个分片，每个分片可有零个或多个副本。集群中的每个数据节点都可承载一个或多个分片，并且协调和处理各种操作； 负载再平衡和路由在大多数情况下自动完成。 3）可以扩展到上百台服务器，处理PB级别的结构化或非结构化数据。也可以运行在单台PC上（已测试） 4）支持插件机制，分词插件、同步插件、Hadoop插件、可视化插件等。 1.9 ES性能结果展示（1）硬件配置： CPU 16核 AuthenticAMD 内存 总量：32GB 硬盘 总量：500GB 非SSD （2）在上述硬件指标的基础上测试性能如下： 1）平均索引吞吐量： 12307docs/s（每个文档大小：40B/docs） 2）平均CPU使用率： 887.7%（16核，平均每核：55.48%） 3）构建索引大小： 3.30111 GB 4）总写入量： 20.2123 GB 5）测试总耗时： 28m 54s. 1.10 性能esrally工具（推荐）使用参考：http://blog.csdn.net/laoyang360/article/details/52155481 1.11 为什么要用ES？ ES国内外使用优秀案例1） 2013年初，GitHub抛弃了Solr，采取ElasticSearch 来做PB级的搜索。 “GitHub使用ElasticSearch搜索20TB的数据，包括13亿文件和1300亿行代码”。 2）维基百科：启动以elasticsearch为基础的核心搜索架构。 3）SoundCloud：“SoundCloud使用ElasticSearch为1.8亿用户提供即时而精准的音乐搜索服务”。 4）百度：百度目前广泛使用ElasticSearch作为文本数据分析，采集百度所有服务器上的各类指标数据及用户自定义数据，通过对各种数据进行多维分析展示，辅助定位分析实例异常或业务层面异常。目前覆盖百度内部20多个业务线（包括casio、云分析、网盟、预测、文库、直达号、钱包、风控等），单集群最大100台机器，200个ES节点，每天导入30TB+数据。 我们也需要实际项目开发实战中，几乎每个系统都会有一个搜索的功能，当搜索做到一定程度时，维护和扩展起来难度就会慢慢变大，所以很多公司都会把搜索单独独立出一个模块，用ElasticSearch等来实现。 近年ElasticSearch发展迅猛，已经超越了其最初的纯搜索引擎的角色，现在已经增加了数据聚合分析（aggregation）和可视化的特性，如果你有数百万的文档需要通过关键词进行定位时，ElasticSearch肯定是最佳选择。当然，如果你的文档是JSON的，你也可以把ElasticSearch当作一种“NoSQL数据库”， 应用ElasticSearch数据聚合分析（aggregation）的特性，针对数据进行多维度的分析。 【知乎：热酷架构师潘飞】ES在某些场景下替代传统DB 个人以为Elasticsearch作为内部存储来说还是不错的，效率也基本能够满足，在某些方面替代传统DB也是可以的，前提是你的业务不对操作的事性务有特殊要求；而权限管理也不用那么细，因为ES的权限这块还不完善。 由于我们对ES的应用场景仅仅是在于对某段时间内的数据聚合操作，没有大量的单文档请求（比如通过userid来找到一个用户的文档，类似于NoSQL的应用场景），所以能否替代NoSQL还需要各位自己的测试。 如果让我选择的话，我会尝试使用ES来替代传统的NoSQL，因为它的横向扩展机制太方便了。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04安装Docker]]></title>
    <url>%2F2018%2F05%2F03%2F%E5%AE%89%E8%A3%85docker%2F</url>
    <content type="text"><![CDATA[一、准备Docker 要求 Ubuntu 系统的内核版本高于 3.10,通过下面的命令查看内核版本： $ uname -r 二、安装1. 卸载旧版本Docker 的旧版本名称为：docker 、 docker-engine 或者 docekr-io。如果安装过旧版本的需要先卸载： $ sudo apt-get remove docker docker-engine docker.io 2. 安装最新版本的 Docker最新版本的 Docker 分两个版本，docker-ce(Community Edition)和docker-ee(Enterprise Edition)。CE版本是免费的，如果我们学习或者一般应用，CE足够。我们安装社区版： 由于docker安装需要使用https，所以需要使 apt 支持 https 的拉取方式。 2.1 安装 https 相关的软件包$ sudo apt-get update # 先更新一下软件源库信息 $ sudo apt-get install \ apt-transport-https \ ca-certificates \ curl \ software-properties-common 2.2 设置apt仓库地址鉴于国内网络问题，强烈建议使用国内地址 1.添加 Docker 官方apt仓库（使用国外源）执行该命令时，如遇到长时间没有响应说明网络连接不到docker网站，需要使用国内的 # 添加 Docker 官方的 GPG 密钥（为了确认所下载软件包的合法性，需要添加软件源的 GPG 密钥） $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - # 设置稳定版本的apt仓库地址 $ sudo add-apt-repository \ &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) \ stable&quot; 2.添加 阿里云 的apt仓库（使用国内源） $ curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - $ sudo add-apt-repository \ &quot;deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu \ $(lsb_release -cs) \ stable&quot; 2.3 安装 Docker 软件 $ sudo apt-get update $ sudo apt-get install docker-ce # 安装最新版的docker 如果要安装指定版本的docker，则使用下面的命令： $ apt-cache policy docker-ce # 查看可供安装的所有docker版本 $ sudo apt-get install docker-ce=18.03.0~ce-0~ubuntu # 安装指定版本的docker 2.4 检查docker是否安装成功$ docker --version # 查看安装的docker版本******** 设置docker容器在启动docker后自启动，后面为容器iddocker update –restart=always ea653e02dce1测试：service docker restart]]></content>
  </entry>
  <entry>
    <title><![CDATA[docker+springboot+zookeeper]]></title>
    <url>%2F2018%2F04%2F13%2Fdockers%2F</url>
    <content type="text"><![CDATA[环境：在windows上开发jar，然后远程阿里云ECS的docker并部署。1：在idea安装docker插件：Docker integration2：要先在阿里云服务器上开启docker的2375监听3：在项目src/main下面新建文件夹docker，把打包好的jar包丢进去（打包的时候注意yml里配置了什么端口，我这里是9070），然后新建Dockerfile，内容 FROM frolvlad/alpine-oraclejdk8:slim VOLUME /tmp ADD cars.jar /usr/cars.jar EXPOSE 9070 CMD java -Djava.security.egd=file:/dev/./urandom -jar /usr/cars.jar 其中EXPOSE 9070表示暴露9070端口。4：5：最后run！6：如果有zookeeper的话。记得代码里xml配置里的&lt;dubbo:registry address=&quot;zookeeper://127.0.0.1:2181&quot; id=&quot;dubbo-registry&quot; /&gt; 这个要修改成&lt;dubbo:registry address=&quot;zookeeper://阿里云公网ip:2181&quot; id=&quot;dubbo-registry&quot; /&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[初探docker]]></title>
    <url>%2F2018%2F04%2F11%2Fdock%2F</url>
    <content type="text"><![CDATA[1：下载镜像imagesdocker pull mysql 2：查看所有镜像docker images 3：安装镜像docker run --name mysql -p 3306:3306 -e MYSQL\_ROOT\_PASSWORD=root -d mysql （其中--name表示安装后的容器名字，-e是mysql的密码配置，-d表示要安装哪一个镜像,-p表示将容器内的3306端口(第二个)映射到主机的3306端口上(第一个)） 4：删除镜像首先要停止容器： docker stop mysql然后删除： docker rm mysql 5：开启容器：docker start python ！！！！注意run和start的区别：run命令表示安装镜像，它包括了将镜像放入容器中（docker create）,然后将容器启动，使之变成运行时容器（docker start）。所以每次执行run都会新建一个容器。。。。。。docker run 只在第一次运行时使用，将镜像放到容器中，以后再次启动这个容器时，只需要使用命令docker start 即可。 6：进入容器docker exec -it java /bin/bashdocker exec -it python python -t：进入终端-i：获得一个交互式的连接，通过获取container的输入/bin/bash：java的命令，python: python的命令， 退出docker容器:Ctrl+D 7：关闭容器docker stop python]]></content>
  </entry>
  <entry>
    <title><![CDATA[高性能队列——Disruptor]]></title>
    <url>%2F2018%2F04%2F10%2F%E9%AB%98%E6%80%A7%E8%83%BD%E9%98%9F%E5%88%97%E2%80%94%E2%80%94Disruptor%2F</url>
    <content type="text"><![CDATA[背景Disruptor是英国外汇交易公司LMAX开发的一个高性能队列，研发的初衷是解决内存队列的延迟问题（在性能测试中发现竟然与I/O操作处于同样的数量级）。基于Disruptor开发的系统单线程能支撑每秒600万订单，2010年在QCon演讲后，获得了业界关注。2011年，企业应用软件专家Martin Fowler专门撰写长文介绍。同年它还获得了Oracle官方的Duke大奖。 目前，包括Apache Storm、Camel、Log4j 2在内的很多知名项目都应用了Disruptor以获取高性能。在美团点评技术团队它也有不少应用，有的项目架构借鉴了它的设计机制。本文从实战角度剖析了Disruptor的实现原理。 需要特别指出的是，这里所说的队列是系统内部的内存队列，而不是Kafka这样的分布式队列。另外，本文所描述的Disruptor特性限于3.3.4。 Java内置队列介绍Disruptor之前，我们先来看一看常用的线程安全的内置队列有什么问题。Java的内置队列如下表所示。 队列 有界性 锁 数据结构 ArrayBlockingQueue bounded 加锁 arraylist LinkedBlockingQueue optionally-bounded 加锁 linkedlist ConcurrentLinkedQueue unbounded 无锁 linkedlist LinkedTransferQueue unbounded 无锁 linkedlist PriorityBlockingQueue unbounded 加锁 heap DelayQueue unbounded 加锁 heap 队列的底层一般分成三种：数组、链表和堆。其中，堆一般情况下是为了实现带有优先级特性的队列，暂且不考虑。 我们就从数组和链表两种数据结构来看，基于数组线程安全的队列，比较典型的是ArrayBlockingQueue，它主要通过加锁的方式来保证线程安全；基于链表的线程安全队列分成LinkedBlockingQueue和ConcurrentLinkedQueue两大类，前者也通过锁的方式来实现线程安全，而后者以及上面表格中的LinkedTransferQueue都是通过原子变量compare and swap（以下简称“CAS”）这种不加锁的方式来实现的。 通过不加锁的方式实现的队列都是无界的（无法保证队列的长度在确定的范围内）；而加锁的方式，可以实现有界队列。在稳定性要求特别高的系统中，为了防止生产者速度过快，导致内存溢出，只能选择有界队列；同时，为了减少Java的垃圾回收对系统性能的影响，会尽量选择array/heap格式的数据结构。这样筛选下来，符合条件的队列就只有ArrayBlockingQueue。 ArrayBlockingQueue的问题ArrayBlockingQueue在实际使用过程中，会因为加锁和伪共享等出现严重的性能问题，我们下面来分析一下。 加锁现实编程过程中，加锁通常会严重地影响性能。线程会因为竞争不到锁而被挂起，等锁被释放的时候，线程又会被恢复，这个过程中存在着很大的开销，并且通常会有较长时间的中断，因为当一个线程正在等待锁时，它不能做任何其他事情。如果一个线程在持有锁的情况下被延迟执行，例如发生了缺页错误、调度延迟或者其它类似情况，那么所有需要这个锁的线程都无法执行下去。如果被阻塞线程的优先级较高，而持有锁的线程优先级较低，就会发生优先级反转。 Disruptor论文中讲述了一个实验： 这个测试程序调用了一个函数，该函数会对一个64位的计数器循环自增5亿次。 机器环境：2.4G 6核 运算： 64位的计数器累加5亿次 Method Time (ms) Single thread 300 Single thread with CAS 5,700 Single thread with lock 10,000 Single thread with volatile write 4,700 Two threads with CAS 30,000 Two threads with lock 224,000 CAS操作比单线程无锁慢了1个数量级；有锁且多线程并发的情况下，速度比单线程无锁慢3个数量级。可见无锁速度最快。 单线程情况下，不加锁的性能 &gt; CAS操作的性能 &gt; 加锁的性能。 在多线程情况下，为了保证线程安全，必须使用CAS或锁，这种情况下，CAS的性能超过锁的性能，前者大约是后者的8倍。 综上可知，加锁的性能是最差的。 关于锁和CAS保证线程安全一般分成两种方式：锁和原子变量。 锁图1 通过加锁的方式实现线程安全采取加锁的方式，默认线程会冲突，访问数据时，先加上锁再访问，访问之后再解锁。通过锁界定一个临界区，同时只有一个线程进入。如上图所示，Thread2访问Entry的时候，加了锁，Thread1就不能再执行访问Entry的代码，从而保证线程安全。 下面是ArrayBlockingQueue通过加锁的方式实现的offer方法，保证线程安全。 123456789101112131415public boolean offer(E e) &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lock(); try &#123; if (count == items.length) return false; else &#123; insert(e); return true; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125; 原子变量原子变量能够保证原子性的操作，意思是某个任务在执行过程中，要么全部成功，要么全部失败回滚，恢复到执行之前的初态，不存在初态和成功之间的中间状态。例如CAS操作，要么比较并交换成功，要么比较并交换失败。由CPU保证原子性。 通过原子变量可以实现线程安全。执行某个任务的时候，先假定不会有冲突，若不发生冲突，则直接执行成功；当发生冲突的时候，则执行失败，回滚再重新操作，直到不发生冲突。 图2 通过原子变量CAS实现线程安全如图所示，Thread1和Thread2都要把Entry加1。若不加锁，也不使用CAS，有可能Thread1取到了myValue=1，Thread2也取到了myValue=1，然后相加，Entry中的value值为2。这与预期不相符，我们预期的是Entry的值经过两次相加后等于3。 CAS会先把Entry现在的value跟线程当初读出的值相比较，若相同，则赋值；若不相同，则赋值执行失败。一般会通过while/for循环来重新执行，直到赋值成功。 代码示例是AtomicInteger的getAndAdd方法。CAS是CPU的一个指令，由CPU保证原子性。 123456789101112131415161718192021222324252627/** * Atomically adds the given value to the current value. * * @param delta the value to add * @return the previous value */public final int getAndAdd(int delta) &#123; for (;;) &#123; int current = get(); int next = current + delta; if (compareAndSet(current, next)) return current; &#125;&#125;/** * Atomically sets the value to the given updated value * if the current value &#123;@code ==&#125; the expected value. * * @param expect the expected value * @param update the new value * @return true if successful. False return indicates that * the actual value was not equal to the expected value. */public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update);&#125; 在高度竞争的情况下，锁的性能将超过原子变量的性能，但是更真实的竞争情况下，原子变量的性能将超过锁的性能。同时原子变量不会有死锁等活跃性问题。 伪共享什么是共享下图是计算的基本结构。L1、L2、L3分别表示一级缓存、二级缓存、三级缓存，越靠近CPU的缓存，速度越快，容量也越小。所以L1缓存很小但很快，并且紧靠着在使用它的CPU内核；L2大一些，也慢一些，并且仍然只能被一个单独的CPU核使用；L3更大、更慢，并且被单个插槽上的所有CPU核共享；最后是主存，由全部插槽上的所有CPU核共享。 图3 计算机CPU与缓存示意图当CPU执行运算的时候，它先去L1查找所需的数据、再去L2、然后是L3，如果最后这些缓存中都没有，所需的数据就要去主内存拿。走得越远，运算耗费的时间就越长。所以如果你在做一些很频繁的事，你要尽量确保数据在L1缓存中。 另外，线程之间共享一份数据的时候，需要一个线程把数据写回主存，而另一个线程访问主存中相应的数据。 下面是从CPU访问不同层级数据的时间概念: 从CPU到 大约需要的CPU周期 大约需要的时间 主存 约60-80ns QPI 总线传输(between sockets, not drawn) 约20ns L3 cache 约40-45 cycles 约15ns L2 cache 约10 cycles 约3ns L1 cache 约3-4 cycles 约1ns 寄存器 1 cycle 可见CPU读取主存中的数据会比从L1中读取慢了近2个数量级。 缓存行Cache是由很多个cache line组成的。每个cache line通常是64字节，并且它有效地引用主内存中的一块儿地址。一个Java的long类型变量是8字节，因此在一个缓存行中可以存8个long类型的变量。 CPU每次从主存中拉取数据时，会把相邻的数据也存入同一个cache line。 在访问一个long数组的时候，如果数组中的一个值被加载到缓存中，它会自动加载另外7个。因此你能非常快的遍历这个数组。事实上，你可以非常快速的遍历在连续内存块中分配的任意数据结构。 下面的例子是测试利用cache line的特性和不利用cache line的特性的效果对比。 12345678910111213141516171819202122232425262728293031323334353637package com.meituan.FalseSharing;/** * @author gongming * @description * @date 16/6/4 */public class CacheLineEffect &#123; //考虑一般缓存行大小是64字节，一个 long 类型占8字节 static long[][] arr; public static void main(String[] args) &#123; arr = new long[1024 * 1024][]; for (int i = 0; i &lt; 1024 * 1024; i++) &#123; arr[i] = new long[8]; for (int j = 0; j &lt; 8; j++) &#123; arr[i][j] = 0L; &#125; &#125; long sum = 0L; long marked = System.currentTimeMillis(); for (int i = 0; i &lt; 1024 * 1024; i+=1) &#123; for(int j =0; j&lt; 8;j++)&#123; sum = arr[i][j]; &#125; &#125; System.out.println("Loop times:" + (System.currentTimeMillis() - marked) + "ms"); marked = System.currentTimeMillis(); for (int i = 0; i &lt; 8; i+=1) &#123; for(int j =0; j&lt; 1024 * 1024;j++)&#123; sum = arr[j][i]; &#125; &#125; System.out.println("Loop times:" + (System.currentTimeMillis() - marked) + "ms"); &#125;&#125; 在2G Hz、2核、8G内存的运行环境中测试，速度差一倍。 结果：Loop times:30msLoop times:65ms 什么是伪共享ArrayBlockingQueue有三个成员变量： takeIndex：需要被取走的元素下标 putIndex：可被元素插入的位置的下标 count：队列中元素的数量 这三个变量很容易放到一个缓存行中，但是之间修改没有太多的关联。所以每次修改，都会使之前缓存的数据失效，从而不能完全达到共享的效果。 图4 ArrayBlockingQueue伪共享示意图如上图所示，当生产者线程put一个元素到ArrayBlockingQueue时，putIndex会修改，从而导致消费者线程的缓存中的缓存行无效，需要从主存中重新读取。 这种无法充分使用缓存行特性的现象，称为伪共享。 对于伪共享，一般的解决方案是，增大数组元素的间隔使得由不同线程存取的元素位于不同的缓存行上，以空间换时间。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package com.meituan.FalseSharing;public class FalseSharing implements Runnable&#123; public final static long ITERATIONS = 500L * 1000L * 100L; private int arrayIndex = 0; private static ValuePadding[] longs; public FalseSharing(final int arrayIndex) &#123; this.arrayIndex = arrayIndex; &#125; public static void main(final String[] args) throws Exception &#123; for(int i=1;i&lt;10;i++)&#123; System.gc(); final long start = System.currentTimeMillis(); runTest(i); System.out.println("Thread num "+i+" duration = " + (System.currentTimeMillis() - start)); &#125; &#125; private static void runTest(int NUM_THREADS) throws InterruptedException &#123; Thread[] threads = new Thread[NUM_THREADS]; longs = new ValuePadding[NUM_THREADS]; for (int i = 0; i &lt; longs.length; i++) &#123; longs[i] = new ValuePadding(); &#125; for (int i = 0; i &lt; threads.length; i++) &#123; threads[i] = new Thread(new FalseSharing(i)); &#125; for (Thread t : threads) &#123; t.start(); &#125; for (Thread t : threads) &#123; t.join(); &#125; &#125; public void run() &#123; long i = ITERATIONS + 1; while (0 != --i) &#123; longs[arrayIndex].value = 0L; &#125; &#125; public final static class ValuePadding &#123; protected long p1, p2, p3, p4, p5, p6, p7; protected volatile long value = 0L; protected long p9, p10, p11, p12, p13, p14; protected long p15; &#125; public final static class ValueNoPadding &#123; // protected long p1, p2, p3, p4, p5, p6, p7; protected volatile long value = 0L; // protected long p9, p10, p11, p12, p13, p14, p15; &#125;&#125; 在2G Hz，2核，8G内存, jdk 1.7.0_45 的运行环境下，使用了共享机制比没有使用共享机制，速度快了4倍左右。 结果：Thread num 1 duration = 447Thread num 2 duration = 463Thread num 3 duration = 454Thread num 4 duration = 464Thread num 5 duration = 561Thread num 6 duration = 606Thread num 7 duration = 684Thread num 8 duration = 870Thread num 9 duration = 823 把代码中ValuePadding都替换为ValueNoPadding后的结果：Thread num 1 duration = 446Thread num 2 duration = 2549Thread num 3 duration = 2898Thread num 4 duration = 3931Thread num 5 duration = 4716Thread num 6 duration = 5424Thread num 7 duration = 4868Thread num 8 duration = 4595Thread num 9 duration = 4540 备注：在jdk1.8中，有专门的注解@Contended来避免伪共享，更优雅地解决问题。 Disruptor的设计方案Disruptor通过以下设计来解决队列速度慢的问题： 环形数组结构 为了避免垃圾回收，采用数组而非链表。同时，数组对处理器的缓存机制更加友好。 元素位置定位 数组长度2^n，通过位运算，加快定位的速度。下标采取递增的形式。不用担心index溢出的问题。index是long类型，即使100万QPS的处理速度，也需要30万年才能用完。 无锁设计 每个生产者或者消费者线程，会先申请可以操作的元素在数组中的位置，申请到之后，直接在该位置写入或者读取数据。 下面忽略数组的环形结构，介绍一下如何实现无锁设计。整个过程通过原子变量CAS，保证操作的线程安全。 一个生产者写数据生产者单线程写数据的流程比较简单： 申请写入m个元素； 若是有m个元素可以写入，则返回最大的序列号。这儿主要判断是否会覆盖未读的元素； 若是返回的正确，则生产者开始写入元素。图5 单个生产者生产过程示意图多个生产者多个生产者的情况下，会遇到“如何防止多个线程重复写同一个元素”的问题。Disruptor的解决方法是，每个线程获取不同的一段数组空间进行操作。这个通过CAS很容易达到。只需要在分配元素的时候，通过CAS判断一下这段空间是否已经分配出去即可。 但是会遇到一个新问题：如何防止读取的时候，读到还未写的元素。Disruptor在多个生产者的情况下，引入了一个与Ring Buffer大小相同的buffer：available Buffer。当某个位置写入成功的时候，便把availble Buffer相应的位置置位，标记为写入成功。读取的时候，会遍历available Buffer，来判断元素是否已经就绪。 下面分读数据和写数据两种情况介绍。 读数据生产者多线程写入的情况会复杂很多： 申请读取到序号n； 若writer cursor &gt;= n，这时仍然无法确定连续可读的最大下标。从reader cursor开始读取available Buffer，一直查到第一个不可用的元素，然后返回最大连续可读元素的位置； 消费者读取元素。 如下图所示，读线程读到下标为2的元素，三个线程Writer1/Writer2/Writer3正在向RingBuffer相应位置写数据，写线程被分配到的最大元素下标是11。 读线程申请读取到下标从3到11的元素，判断writer cursor&gt;=11。然后开始读取availableBuffer，从3开始，往后读取，发现下标为7的元素没有生产成功，于是WaitFor(11)返回6。 然后，消费者读取下标从3到6共计4个元素。 图6 多个生产者情况下，消费者消费过程示意图 写数据多个生产者写入的时候： 申请写入m个元素； 若是有m个元素可以写入，则返回最大的序列号。每个生产者会被分配一段独享的空间； 生产者写入元素，写入元素的同时设置available Buffer里面相应的位置，以标记自己哪些位置是已经写入成功的。 如下图所示，Writer1和Writer2两个线程写入数组，都申请可写的数组空间。Writer1被分配了下标3到下表5的空间，Writer2被分配了下标6到下标9的空间。 Writer1写入下标3位置的元素，同时把available Buffer相应位置置位，标记已经写入成功，往后移一位，开始写下标4位置的元素。Writer2同样的方式。最终都写入完成。 图7 多个生产者情况下，生产者生产过程示意图防止不同生产者对同一段空间写入的代码，如下所示： 123456789101112131415161718192021222324public long tryNext(int n) throws InsufficientCapacityException&#123; if (n &lt; 1) &#123; throw new IllegalArgumentException("n must be &gt; 0"); &#125; long current; long next; do &#123; current = cursor.get(); next = current + n; if (!hasAvailableCapacity(gatingSequences, n, current)) &#123; throw InsufficientCapacityException.INSTANCE; &#125; &#125; while (!cursor.compareAndSet(current, next)); return next;&#125; 通过do/while循环的条件cursor.compareAndSet(current, next)，来判断每次申请的空间是否已经被其他生产者占据。假如已经被占据，该函数会返回失败，While循环重新执行，申请写入空间。 消费者的流程与生产者非常类似，这儿就不多描述了。 总结Disruptor通过精巧的无锁设计实现了在高并发情形下的高性能。 在美团点评内部，很多高并发场景借鉴了Disruptor的设计，减少竞争的强度。其设计思想可以扩展到分布式场景，通过无锁设计，来提升服务性能。 代码样例使用Disruptor比使用ArrayBlockingQueue略微复杂，为方便读者上手，增加代码样例。 代码实现的功能：每10ms向disruptor中插入一个元素，消费者读取数据，并打印到终端。详细逻辑请细读代码。 以下代码基于3.3.4版本的Disruptor包。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192package com.meituan.Disruptor;/** * @description disruptor代码样例。每10ms向disruptor中插入一个元素，消费者读取数据，并打印到终端 */import com.lmax.disruptor.*;import com.lmax.disruptor.dsl.Disruptor;import com.lmax.disruptor.dsl.ProducerType;import java.util.concurrent.ThreadFactory;public class DisruptorMain&#123; public static void main(String[] args) throws Exception &#123; // 队列中的元素 class Element &#123; private int value; public int get()&#123; return value; &#125; public void set(int value)&#123; this.value= value; &#125; &#125; // 生产者的线程工厂 ThreadFactory threadFactory = new ThreadFactory()&#123; @Override public Thread newThread(Runnable r) &#123; return new Thread(r, "simpleThread"); &#125; &#125;; // RingBuffer生产工厂,初始化RingBuffer的时候使用 EventFactory&lt;Element&gt; factory = new EventFactory&lt;Element&gt;() &#123; @Override public Element newInstance() &#123; return new Element(); &#125; &#125;; // 处理Event的handler EventHandler&lt;Element&gt; handler = new EventHandler&lt;Element&gt;()&#123; @Override public void onEvent(Element element, long sequence, boolean endOfBatch) &#123; System.out.println("Element: " + element.get()); &#125; &#125;; // 阻塞策略 BlockingWaitStrategy strategy = new BlockingWaitStrategy(); // 指定RingBuffer的大小 int bufferSize = 16; // 创建disruptor，采用单生产者模式 Disruptor&lt;Element&gt; disruptor = new Disruptor(factory, bufferSize, threadFactory, ProducerType.SINGLE, strategy); // 设置EventHandler disruptor.handleEventsWith(handler); // 启动disruptor的线程 disruptor.start(); RingBuffer&lt;Element&gt; ringBuffer = disruptor.getRingBuffer(); for (int l = 0; true; l++) &#123; // 获取下一个可用位置的下标 long sequence = ringBuffer.next(); try &#123; // 返回可用位置的元素 Element event = ringBuffer.get(sequence); // 设置该位置元素的值 event.set(l); &#125; finally &#123; ringBuffer.publish(sequence); &#125; Thread.sleep(10); &#125; &#125;&#125; 性能以下面这些模式测试性能: 吞吐量测试数据（每秒的数量）如下。 环境： CPU:Intel Core i7 860 @ 2.8 GHz without HT JVM:Java 1.6.0_25 64-bit OS:Windows 7 ABQ Disruptor Unicast: 1P – 1C 5,339,256 25,998,336 Pipeline: 1P – 3C 2,128,918 16,806,157 Sequencer: 3P – 1C 5,539,531 13,403,268 Multicast: 1P – 3C 1,077,384 9,377,871 Diamond: 1P – 3C 2,113,941 16,143,613 环境： CPU:Intel Core i7-2720QM JVM:Java 1.6.0_25 64-bit OS:Ubuntu 11.04 ABQ Disruptor Unicast: 1P – 1C 4,057,453 22,381,378 Pipeline: 1P – 3C 2,006,903 15,857,913 Sequencer: 3P – 1C 2,056,118 14,540,519 Multicast: 1P – 3C 260,733 10,860,121 Diamond: 1P – 3C 2,082,725 15,295,197 依据并发竞争的激烈程度的不同，Disruptor比ArrayBlockingQueue吞吐量快4~7倍。 按照Pipeline: 1P – 3C的连接模式测试延迟，生产者两次写入之间的延迟为1ms。 运行环境： CPU:2.2GHz Core i7-2720QM Java: 1.6.0_25 64-bit OS:Ubuntu 11.04. Array Blocking Queue (ns) Disruptor (ns) 99% observations less than 2,097,152 128 99.99% observations less than 4,194,304 8,192 Max Latency 5,069,086 175,567 Mean Latency 32,757 52 Min Latency 145 29 可见，平均延迟差了3个数量级。 等待策略生产者的等待策略暂时只有休眠1ns。 1LockSupport.parkNanos(1); 消费者的等待策略 名称 措施 适用场景 BlockingWaitStrategy 加锁 CPU资源紧缺，吞吐量和延迟并不重要的场景 BusySpinWaitStrategy 自旋 通过不断重试，减少切换线程导致的系统调用，而降低延迟。推荐在线程绑定到固定的CPU的场景下使用 PhasedBackoffWaitStrategy 自旋 + yield + 自定义策略 CPU资源紧缺，吞吐量和延迟并不重要的场景 SleepingWaitStrategy 自旋 + yield + sleep 性能和CPU资源之间有很好的折中。延迟不均匀 TimeoutBlockingWaitStrategy 加锁，有超时限制 CPU资源紧缺，吞吐量和延迟并不重要的场景 YieldingWaitStrategy 自旋 + yield + 自旋 性能和CPU资源之间有很好的折中。延迟比较均匀 Log4j 2应用场景Log4j 2相对于Log4j 1最大的优势在于多线程并发场景下性能更优。该特性源自于Log4j 2的异步模式采用了Disruptor来处理。在Log4j 2的配置文件中可以配置WaitStrategy，默认是Timeout策略。下面是Log4j 2中对WaitStrategy的配置官方文档： System Property Default Value Description AsyncLogger.WaitStrategy Timeout Valid values: Block, Timeout, Sleep, Yield. Block is a strategy that uses a lock and condition variable for the I/O thread waiting for log events. Block can be used when throughput and low-latency are not as important as CPU resource. Recommended for resource constrained/virtualised environments. Timeout is a variation of the Block strategy that will periodically wake up from the lock condition await() call. This ensures that if a notification is missed somehow the consumer thread is not stuck but will recover with a small latency delay (default 10ms). Sleep is a strategy that initially spins, then uses a Thread.yield(), and eventually parks for the minimum number of nanos the OS and JVM will allow while the I/O thread is waiting for log events. Sleep is a good compromise between performance and CPU resource. This strategy has very low impact on the application thread, in exchange for some additional latency for actually getting the message logged. Yield is a strategy that uses a Thread.yield() for waiting for log events after an initially spinning. Yield is a good compromise between performance and CPU resource, but may use more CPU than Sleep in order to get the message logged to disk sooner. 性能差异loggers all async采用的是Disruptor，而Async Appender采用的是ArrayBlockingQueue队列。 由图可见，单线程情况下，loggers all async与Async Appender吞吐量相差不大，但是在64个线程的时候，loggers all async的吞吐量比Async Appender增加了12倍，是Sync模式的68倍。 图8 Log4j 2各个模式性能比较美团点评在公司内部统一推行日志接入规范，要求必须使用Log4j 2，使普通单机QPS的上限不再只停留在几千，极高地提升了服务性能。 参考文档https://tech.meituan.com/disruptor.htmlhttp://brokendreams.iteye.com/blog/2255720http://ifeve.com/dissecting-disruptor-whats-so-special/https://github.com/LMAX-Exchange/disruptor/wiki/Performance-Resultshttps://lmax-exchange.github.io/disruptor/https://logging.apache.org/log4j/2.x/manual/async.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[linux定时重启java项目]]></title>
    <url>%2F2018%2F03%2F31%2Flinux%E5%AE%9A%E6%97%B6%E9%87%8D%E5%90%AFjava%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[Linux定时重启java项目———crontab基本命令：crontab -e：编辑crontab -l：状态crontab -r：删除 第一步：实现：每天晚上23:59分，打开项目jar目录，并且运行重启jar的脚本。59 23 * * * cd /usr/local/doordata &amp;&amp; ./auto.sh 坑1：* * * * * 每分钟执行可以，但是 1 * * * * *就不行，01 * * * * *也不行。坑2：可以运行shell了，但是shell里的java -jar doordata.jar识别不了，要把java路径带上，先输出看一下echo $JAVA_HOME，最后改为/usr/java/jdk1.7.0_76/bin/java -jar doordata.jar 第二步：实现找到项目的pid，如果不为空就kill，并且重新启动。如果为空，直接启动。 #!/bin/sh pid=`ps aux | grep doordata| grep -v grep | grep -v Restart | grep -v restart | awk &apos;{print $2}&apos;` echo &quot;the doordata pid is $pid&quot; #判断doordata进程是否存在 if [ -n &quot;$pid&quot; ];then sleep 1 pid=`ps aux | grep doordata | grep -v grep | grep -v restart | grep -v Restart | awk &apos;{print $2}&apos;` if [ -n &quot;$pid&quot; ]; then sleep 1 echo &quot;doordata进程将被杀死.&quot; kill -9 $pid fi sleep 1 echo &quot;doordata进程已经被杀死，先重新启动doordata.&quot; nohup /usr/java/jdk1.7.0_76/bin/java -jar doordata.jar &gt;log.txt 2&gt;&amp;1 &amp; else echo &quot;doordata进程不存在，先重新启动doordata.&quot; nohup /usr/java/jdk1.7.0_76/bin/java -jar doordata.jar &gt;log.txt 2&gt;&amp;1 &amp; fi 第三步：明晚上23:59分检查一下是否重启了。]]></content>
  </entry>
  <entry>
    <title><![CDATA[顺时针旋转]]></title>
    <url>%2F2018%2F03%2F30%2F%E9%A1%BA%E6%97%B6%E9%92%88%E6%97%8B%E8%BD%AC%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.example.demo;import java.util.Scanner;/** * @Project: demo * @Package: com.example.demo * @Date : 2018/3/30 13:01 * @Author : Simeon */public class 任意矩阵顺时针旋转90度 &#123;// 1 2 3 4 2 1 5 1// 5 6 7 8 -&gt; 2 1 6 2// 1 1 1 1 2 1 7 3// 2 2 2 2 2 1 8 4 public static void get11(String[][] a)&#123; int p =a[0].length; for (int i=0;i&lt;p;i++)&#123; for (int j=p-1;j&gt;=0;j--)&#123; System.out.print(a[j][i]+" "); &#125; System.out.println(); &#125; &#125; public static void main(String[] args)&#123; Scanner scanner = new Scanner(System.in); String first = scanner.nextLine(); int a = first.split(" ").length; String[][] b = new String[a][a]; for (int i=0;i&lt;a;i++)&#123; b[0][i] = first.split(" ")[i]; &#125; for (int j=1;j&lt;a;j++)&#123; String[] tem = scanner.nextLine().split(" "); for (int k=0;k&lt;a;k++)&#123; b[j][k] = tem[k]; &#125; &#125; get11(b); &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[蛋糕]]></title>
    <url>%2F2018%2F03%2F19%2F%E8%9B%8B%E7%B3%95%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题描述 小明今天生日，他有n块蛋糕要分给朋友们吃，这n块蛋糕（编号为1到n）的重量分别为a1, a2, …, an。小明想分给每个朋友至少重量为k的蛋糕。小明的朋友们已经排好队准备领蛋糕，对于每个朋友，小明总是先将自己手中编号最小的蛋糕分给他，当这个朋友所分得蛋糕的重量不到k时，再继续将剩下的蛋糕中编号最小的给他，直到小明的蛋糕分完或者这个朋友分到的蛋糕的总重量大于等于k。 请问当小明的蛋糕分完时，总共有多少个朋友分到了蛋糕。 输入格式 输入的第一行包含了两个整数n, k，意义如上所述。 第二行包含n个正整数，依次表示a1, a2, …, an。 输出格式 输出一个整数，表示有多少个朋友分到了蛋糕。 样例输入6 92 6 5 6 3 5 样例输出3 样例说明 第一个朋友分到了前3块蛋糕，第二个朋友分到了第4、5块蛋糕，第三个朋友分到了最后一块蛋糕。 评测用例规模与约定 对于所有评测用例，1 ≤ n ≤ 1000，1 ≤ k ≤ 10000，1 ≤ ai ≤ 1000。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.example.demo;import java.util.Scanner;/** * @Project: demo * @Package: com.example.demo * @Date : 2018/3/16 20:56 * @Author : Simeon */public class test &#123; public static int getqq(int i,int n,int[] a,int k)&#123; if (i==n-1)&#123; //如果是最后一个不够，也算数 return i; &#125; int sum = 0; while (i&lt;n)&#123; sum=sum+a[i]; if(sum&gt;=k)&#123; return i; &#125; i++; &#125; return n; &#125; public static void main(String[] args)&#123; System.out.println("输入两个整数n, k（空格分开）："); Scanner in = new Scanner(System.in); int n = in.nextInt(); int[] a = new int[n]; int k = in.nextInt(); System.out.println("输入每个蛋糕重量，（空格分开）："); for (int j=0;j&lt;n;j++)&#123; a[j] = in.nextInt(); &#125; int result=0; int i=0; while(i&lt;n)&#123; i = getqq(i, n, a, k); if (i&lt;n)&#123; result++; &#125; else &#123; break; &#125; i++; //后移一个 &#125; System.out.println(result); &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>蛋糕</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql和oracle分页]]></title>
    <url>%2F2018%2F03%2F15%2Findex%2F</url>
    <content type="text"><![CDATA[http://my.oschina.net/realfighter/blog/349867 http://www.xx566.com/detail/143.html 以前总结过一篇，Oracle分页查询语句的优化，当时对Oracle分页语句也着实花费了点时间记忆，不过今天在面试的时候，又考到了不同数据库的分页sql语句，对Oracle数据库的书写又存在了问题，以为很熟悉的分页sql书写起来也生疏了许多，这里再继续总结和整理一下，加深记忆。Mysql的分页相对Oracle数据库来说，最是简单，通过提供的Limit关键字，即可方便的实现分页，如下：12345SELECT *FROM testTableWHERE 1 = 1LIMIT 1, 20; Oracle的分页sql，传统的是通过rownum，来进行分页，如下：1234567891011SELECT *FROM (SELECT T1.*, ROWNUM rn FROM (SELECT * FROM testTable ORDER BY id DESC) T1 WHERE ROWNUM &lt;= 20)WHERE rn &gt; 0; 不过上面的分页sql在数据量庞大的时候，越往后的分页查询会越缓慢，还有另外的一种效率很高的分页查询，通过rownum和rowid来进行分页，如下：1234567891011121314SELECT t1.*FROM testTable t1, (SELECT rid FROM (SELECT ROWNUM rn, t.rid FROM (SELECT ROWID rid FROM testTable WHERE 1 = 1) t WHERE ROWNUM &lt;= 20) WHERE rn &gt; 0) t2WHERE 1 = 1 AND t1.ROWID = t2.rid; 总结：分页的应用在各式各样的系统中，都是必不可少的组成部分，对分页sql的应用和优化也一直是程序开发中的重要成分，需要不断的记忆和总结。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>分页</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[试水博客]]></title>
    <url>%2F2018%2F03%2F13%2F%E8%AF%95%E6%B0%B4%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[都闪开，我要装*了！ 变小！再变小！继续变小！]]></content>
      <categories>
        <category>测试分类</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>测试</tag>
      </tags>
  </entry>
</search>
